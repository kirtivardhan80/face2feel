# ğŸ˜Š Real-Time Emotion Detection using MobileNetV2 + OpenCV

This project uses a fine-tuned MobileNetV2 model to detect human facial emotions in **images**, **videos**, and **live webcam** streams. It applies deep learning for expression classification and OpenCV for face detection and visual overlay.

---

## ğŸ§  Emotions Detected

- Angry ğŸ˜ 
- Disgust ğŸ¤¢
- Fear ğŸ˜¨
- Happy ğŸ˜„
- Sad ğŸ˜¢
- Surprise ğŸ˜²
- Neutral ğŸ˜

---

## ğŸ› ï¸ Tech Stack

- **TensorFlow / Keras** â€“ For building and training the MobileNetV2 model  
- **OpenCV** â€“ For real-time face detection and visualization  
- **NumPy & Matplotlib** â€“ Data processing and visualization  
- **FER2013 Dataset** â€“ Standard dataset for training emotion recognition

---

## ğŸ“¦ Folder Structure

\`\`\`
Emotion-Detection/
â”‚
â”œâ”€â”€ final_emotion_model.h5              # Trained MobileNetV2 model
â”œâ”€â”€ Emotion_Prediction_MobileNetV2.ipynb # Notebook for prediction & visualization
â”œâ”€â”€ detectedimg.jpg                     # Sample output (auto-generated)
â”œâ”€â”€ README.md                           # This file
â””â”€â”€ dataset/
    â”œâ”€â”€ train/
    â””â”€â”€ test/
\`\`\`

---

## ğŸš€ Features

### âœ… Emotion Prediction from Image
Detects all faces in an image and overlays bounding boxes and predicted emotions with confidence.

\`\`\`python
predict_emotion_from_path("path_to_image.jpg")
\`\`\`

---

### âœ… Live Webcam Emotion Detection *(Updated Feature)*  
Predicts **Top-3 emotions per face with confidence %** in real time, using webcam input.

\`\`\`python
run_webcam_emotion_detection()
\`\`\`

---

### âœ… Video File Emotion Detection
Processes every frame in a video file, detects faces, and predicts emotion with overlay.

\`\`\`python
run_video_emotion_detection("path_to_video.mp4")
\`\`\`

---

### âœ… Sample Output of Expression Prediction

Once a face is detected and emotion is predicted, a sample image (`detectedimg.jpg`) is saved automatically showing bounding box and emotion label.

---

## ğŸ“· Visualization

- Bounding boxes drawn around faces.
- Emotion labels displayed above each face.
- Top-3 emotions (for webcam) with confidence %.
- Emotion-specific color codes:
  - Happy â†’ Green
  - Angry â†’ Red
  - Sad â†’ Blue
  - and so on...

---

## ğŸ’¾ Prediction Sample

### ğŸ–¼ï¸ Images

<p align="center">
  <img src="Images/structure_gan_ti.png" alt="Optimized GaN-Ti Nanotube Structure" width="500"/>
</p>

### ğŸ¥ Videos

<p align="center">
  <img src="Images/band_structure.png" alt="Band Structure Plot" width="500"/>
</p>

### ğŸ“· Webcam

<p align="center">
  <img src="Images/dos_plot.png" alt="Density of States" width="500"/>
</p>


---

## âš ï¸ Note on Accuracy

ğŸ“‰ **Current model accuracy is ~40%**, which means predictions may not always be reliable.  
Improving the modelâ€™s performance is part of future work, including better data preprocessing, augmentation, and fine-tuning.

---

## ğŸ§ª Model Evaluation

To evaluate accuracy on the test set:

\`\`\`python
from tensorflow.keras.preprocessing.image import ImageDataGenerator

test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
    'dataset/test', 
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

loss, accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {accuracy * 100:.2f}%")
\`\`\`

---

## ğŸ”§ Setup Instructions

1. **Clone the repo:**

```bash
git clone https://github.com/yourusername/Emotion-Detection.git
cd Emotion-Detection
```

2. **Install dependencies:**

```bash
pip install tensorflow==2.10.1 opencv-python numpy matplotlib
```

3. **Run the notebook:**

```bash
jupyter notebook Emotion_Prediction_MobileNetV2.ipynb
```

---

## ğŸ’¡ Future Enhancements

| Feature                                | Description |
|----------------------------------------|-------------|
| ğŸŒ Web Deployment (Streamlit/Gradio)   | Deploy model with UI for upload/live webcam |
| ğŸ“ˆ Accuracy Visualizations              | Show confusion matrix, F1 score, precision |
| ğŸ¥ Save Processed Videos                | Export annotated video with timestamped emotions |
| ğŸ“¦ Real-time Logging                    | Store results in CSV or database |
| ğŸ§‘â€ğŸ¤â€ğŸ§‘ Group Face Emotion Analysis       | Show crowd emotion summary |
| ğŸ—£ï¸ Audio + Emotion Fusion               | Combine voice tone and face for better inference |
| ğŸ“± Mobile App Integration               | Deploy using TensorFlow Lite on mobile |
| ğŸ” Model Retraining                     | Improve model performance with more diverse datasets |
| ğŸ¤– Use Better Architecture              | Try EfficientNet or Vision Transformers for higher accuracy |

---

## ğŸ“ License

This project is licensed under the MIT License.

---


## ğŸ™Œ Acknowledgements

- [FER2013 Dataset](https://www.kaggle.com/datasets/msambare/fer2013)
- TensorFlow and OpenCV communities
""")

## ğŸ“¬ Contact

ğŸ‘¤ Kirti Vardhan Singh  
ğŸ“§ Email: kirtivardhan7549@gmail.com  
ğŸ« Department of Computer Science and Engineering  
Centurion University of Technology and Management, Bhubaneswar, India

---

<div align="center">
  Made with â¤ï¸ for materials simulation and nanoscience.
</div>
```
